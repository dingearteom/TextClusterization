{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/normalized_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>но тот кто сведущий в таинство творение не сея...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>часть ввести федеральный закон от 2003 162 фз ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>елисей стоять тихо в сторона сказать вскоре чи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ну девка смочь проговорить сафронов сознательн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>богатство кичиться звенеть серебро и злато бле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>после общий пробуждение в ночлежный барак земл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>я тайна творение в тиша вино открывать вновь о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>и здесь решить быть начать завтра рыть земля н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>деяние предусмотренный часть один или два наст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>чиклин с точность воображать себя горе прушевс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1318 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paragraph_lemmatized\n",
       "0     но тот кто сведущий в таинство творение не сея...\n",
       "1     часть ввести федеральный закон от 2003 162 фз ...\n",
       "2     елисей стоять тихо в сторона сказать вскоре чи...\n",
       "3     ну девка смочь проговорить сафронов сознательн...\n",
       "4     богатство кичиться звенеть серебро и злато бле...\n",
       "...                                                 ...\n",
       "1313  после общий пробуждение в ночлежный барак земл...\n",
       "1314  я тайна творение в тиша вино открывать вновь о...\n",
       "1315  и здесь решить быть начать завтра рыть земля н...\n",
       "1316  деяние предусмотренный часть один или два наст...\n",
       "1317  чиклин с точность воображать себя горе прушевс...\n",
       "\n",
       "[1318 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/artem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "STOPS = set(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32378"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_list = set([line.strip().split(\" \")[2] \n",
    "                  for line in open(\"data/lemma.num\", \"r+\", encoding=\"cp1251\").readlines() \n",
    "                  if line.strip()]).difference(STOPS)\n",
    "\n",
    "len(freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfaa9babfa034937b05f7a22e0b07388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tokens = []\n",
    "raw_vectors = []\n",
    "\n",
    "with open(\"data/182/model.txt\", \"r+\", encoding=\"utf-8\") as rf:\n",
    "    \n",
    "    # пропускаем первую строку\n",
    "    next(rf) \n",
    "    \n",
    "    for line in tqdm(rf):\n",
    "        line = line.strip()\n",
    "        splitted = line.split(\" \") \n",
    "        vector = np.array([float(n) for n in splitted[1:]])\n",
    "        token = splitted[0].split(\"_\")[0]\n",
    "        \n",
    "        if token in freq_list:\n",
    "            tokens.append(token)\n",
    "            raw_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = {t: i for i, t in enumerate(tokens)}\n",
    "vectors = np.array(raw_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docEmbeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    embedding = np.zeros_like(vectors[0])\n",
    "    cnt = 0\n",
    "    for word in df.iat[i, 0].split(' '):\n",
    "        if (word in token2id):\n",
    "            embedding += vectors[token2id[word]]\n",
    "            cnt += 1\n",
    "    embedding /= cnt\n",
    "    docEmbeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docEmbeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
